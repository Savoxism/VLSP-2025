[
  {
    "type": "text",
    "content": "Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced\nRetrieval-Augmented Generation on Knowledge Graphs\nXiaqiang Tang1,2, Jian Li2*,\nNan Du2, Sihong Xie1,*,\n1The Hong Kong University of Science and Technology (Guangzhou)\n2Tencent Hunyuan\nAbstract\nDespite the superior performance of Large language mod-\nels on many NLP tasks, they still face significant limi-\ntations in memorizing extensive world knowledge. Recent\nstudies have demonstrated that leveraging the Retrieval-\nAugmented Generation (RAG) framework, combined with\nKnowledge Graphs that encapsulate extensive factual data in\na structured format, robustly enhances the reasoning capa-\nbilities of LLMs. However, deploying such systems in real-\nworld scenarios presents challenges: the continuous evolu-\ntion of non-stationary environments may lead to performance\ndegradation and user satisfaction requires a careful balance\nof performance and responsiveness. To address these chal-\nlenges, we introduce a Multi-objective Multi-Armed Bandit\nenhanced RAG framework, supported by multiple retrieval\nmethods with diverse capabilities under rich and evolving\nretrieval contexts in practice. Within this framework, each\nretrieval method is treated as a distinct “arm”. The sys-\ntem utilizes real-time user feedback to adapt to dynamic\nenvironments, by selecting the appropriate retrieval method\nbased on input queries and the historical multi-objective\nperformance of each arm. Extensive experiments conducted\non two benchmark KGQA datasets demonstrate that our\nmethod significantly outperforms baseline methods in non-\nstationary settings while achieving state-of-the-art perfor-\nmance in stationary environments. Code and data are avail-\nable at https://github.com/FUTUREEEEEE/Dynamic-RAG\n1\nIntroduction\nLarge language models (LLMs) (Chowdhery et al. 2023;\nOpenAI 2023; Touvron et al. 2023) excel in natural lan-\nguage processing tasks (Bang et al. 2023; Brown et al. 2020)\nbut struggle with knowledge-intensive challenges, often\nproducing unfaithful or hallucinated information (Petroni\net al. 2020; Ji et al. 2023). Retrieval-Augmented Generation\n(RAG) (Lewis et al. 2020) has been developed to enhance\nLLM reasoning, effectively reducing hallucinations and pro-\nviding reliable, up-to-date information. In this approach,\nwhen presented with a user query, a retriever first extracts\nrelevant information from a knowledge base, which is then\nprovided to the LLM to generate the final response.Recent\nadvancements (He et al. 2024; Luo et al. 2023c; Sun et al.\n*Corresponding author\nCopyright © 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n2023; Xu et al. 2024) in RAG systems have increasingly in-\ncorporated Knowledge graphs (KGs) (Baek, Aji, and Saf-\nfari 2023; Luo et al. 2023b) as the underlying knowledge\nbase. KGs store vast amounts of factual data in a structured\nformat, which enables more dependable and systematic rea-\nsoning by LLMs.\nUnlike unstructured text databases (e.g. Wikipedia), the\norganized nature of KGs provides diverse retrieval meth-\nods, with significantly different capabilities and costs. For\nexample, dense retrieval methods (Zhang et al. 2023; Yu\net al. 2022) are typically fast but offer limited reasoning ca-\npabilities. In contrast, using LLMs to generate KG query\nlanguages (e.g., SPARQL) as in ChatKBQA (Luo et al.\n2023a) provides high coverage and is suitable for multi-\nentity retrieval. Methods like RoG (Luo et al. 2023c), where\nLLMs function as search agents excel in complex reasoning.\nHowever, both methods require interactions with LLMs like\nChatGPT (OpenAI 2024), leading to longer execution times.\nHowever, current KG-based RAG systems often rely solely\non a single retrieval method or use static neural network\nrouters (Reis et al. 2019; lla 2024), which require complete\nlabeled data for supervision and periodic fine-tuning. More-\nover, while RAG systems are often deployed in scenarios\nwhere users can provide feedback on generated responses\n(Gamage et al. 2024; Alan, Aydın, and Karaarslan 2024),\ncurrent systems generally neglect this feedback. Relying on\na single retrieval method, or computationally intensive en-\nsemble all retrieval results can not ensure responses that are\nboth timely and informative. On the other hand, static neural\nnetwork routers cannot effectively leverage real-time feed-\nback to continually adapt to changing user needs and system\nvariability.\nTherefore, deploying RAG systems in real-world scenar-\nios faces the following challenges as described in Fig. 1:\n(C1): Non-stationary environments require RAG systems to\nadapt to two sides continuously: on the user side, the evolv-\ning nature of queries driven by trending topics, and on the\nserver side, the backend retrieval model upgrading. (C2): In\npractical applications RAG systems, such as personal home\nassistants and customer support chatbots, balancing multi-\nobjective, such as efficiency, coverage, and reasoning power,\nis crucial to providing informative and satisfying user expe-\nriences. Failing to address the diverse demands of queries\nand deliver timely, comprehensive responses can result in\narXiv:2412.07618v2  [cs.AI]  20 Dec 2024"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p1_1.png"
  },
  {
    "type": "text",
    "content": "Figure 1: An online KG-based RAG system facing challenges from non-stationary environments and the need to balance\nmultiple objectives for optimal user experience.\nless informative interactions or unsatisfying user experience.\nIn response to (C1), we proposed a RAG framework en-\nhanced by deep contextual Multi-arm Bandit(Collier and\nLlorens 2018), utilizing a lightweight language model as\nthe backbone to interpret user queries and predict the suit-\nability of each retrieval method. The model is updated on\na per-query basis using feedback, ensuring robust perfor-\nmance and adaptability in non-stationary environments. In\nresponse to (C2), we incorporated the Generalized Gini In-\ndex to aggregate multi-objective user demands effectively,\nensuring that no single objective dominates the other objec-\ntive. By balancing retrieval coverage, accuracy, and response\ntime, our framework enhances user experience by providing\ninformative answers under time constraints.\nOur main technical contributions are as follows:\n• We enhanced KG-based RAG systems by employing an\nMAB model for dynamic retrieval selection and continu-\nous adaptation to non-stationarity using user feedback.\n• We utilized the Generalized Gini Index to aggregate\nmulti-objective rewards, ensuring both informative and\ntimely responses.\n• We evaluated our framework on two well-established\nKBQA datasets. Our results demonstrate that our meth-\nods significantly outperform baseline approaches in non-\nstationary environments and surpass state-of-the-art KG-\nbased RAG systems in stationary settings.\n2\nMethod\nThe diverse capabilities of different retrieval methods ne-\ncessitate a strategic model for their selection. Simply run-\nning multiple retrievers and then aggregating their results\noften proves sub-optimal due to two main factors: the need\nfor timely responses and the disparate performance charac-\nteristics of various retrieval methods, as highlighted in Ta-\nble 1. For example, while dense retrievers provide rapid re-\nsponses, KG agent-based retrievers slow down the system\ndue to LLM inference.\nConsequently, we developed a model that dynamically as-\nsigns queries to the most suitable retrievers. Unlike static\nneural network routers, which require collecting complete\nlabeled data for supervision (involving the execution of all\nretrieval methods) and periodic fine-tuning, limiting their\nadaptability to non-stationary environments. Our approach\nleverages real-time user feedback as a reward signal to up-\ndate the model. This adaptability is crucial in the dynamic\nnature of RAG applications, such as shifting user interests\nand backend retriever upgrades requiring continuous opti-\nmization.\n2.1\nProblem Setup\nThe optimization of KG-based RAG systems employing\nmultiple retriever backends and real-time feedback is struc-\ntured as follows:\n• Initially, the system receives a user input query context x.\n• The PLM model fθ processes the query and selects an ac-\ntion a from the action space A, which includes K poten-\ntial retrieval methods, each representing an arm in a multi-\narmed bandit.\n• Upon selection, the system receives feedback on the per-\nformance of the chosen retrieval method a (e.g. 1 indicat-\ning a good response, 0 indicating a bad response), pro-\nviding ”partial-information” feedback. This limitation re-\nstricts the system’s ability to assess unselected methods.\n• Utilizing this feedback, the model iteratively refines its\nstrategy to improve base retrieval method selection for fu-\nture queries.\n2.2\nDeep Multi-objective Contextual Bandits\nQuery Encoding Model:\nIn order to effectively select re-\ntrieval methods, it is crucial to discern patterns within user\nqueries and associate these with the capabilities of suitable\nretrieval methods. Traditional linear models in contextual\nbandits (Li et al. 2010; Mehrotra, Xue, and Lalmas 2020),\nwhile effective in certain scenarios, often fall short due to the\ncomplex natural language patterns present in user queries.\nTo address limitations and ensure real-time service, we\nutilize the lightweight Pre-trained Language Model, Distil-\nBERT (Sanh et al. 2019). As a streamlined version of BERT,\nDistilBERT retains approximately 97% of BERT’s language\nunderstanding capabilities and increases processing speed"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p2_3.png"
  },
  {
    "type": "text",
    "content": "Figure 2: Proposed MAB-enhanced RAG framework. The input query undergoes feature extraction (e.g., multi-entity query),\nfollowed by the MAB algorithm, which selects the optimal retrieval method by predicting the most rewarding option (e.g.,\nQuery Language method). The selected method retrieves information from a Knowledge Graph (KG), and an LLM generates\nthe final response. Feedback is collected as a reward, updating the MAB model parameters online, and enabling continuous\nadaptation to non-stationary environments.\nby 60%. This model provides a robust and nuanced approach\nto modeling natural language queries, which facilitates the\nprecise identification of appropriate retrieval methods for in-\ndividual queries and supports continuous real-time refine-\nment through user feedback.\nSpecifically, our query encoding model, fθ, uses Dis-\ntilBERT to efficiently interpret natural language, taking a\nquery as input context and producing an arm selection dis-\ntribution z = fθ(x).\nArm Selection Strategy:\nUpon receiving an action dis-\ntribution estimation z = fθ(x) from the encoding model,\nwe employ an epsilon-greedy strategy (Langford and Zhang\n2007) to balance the trade-off between exploration and\nexploitation (Auer 2002; Auer, Cesa-Bianchi, and Fischer\n2002). This balance is crucial in ensuring that the system\nnot only leverages the information gathered so far (exploit\nknown retrieval methods that have proven effective) but also\nexplores new possibilities to enhance learning (explore other\nretrieval methods that could potentially offer better results).\nSpecifically:\n• With a probability of 1−ϵ, the system selects the arm with\nthe highest predicted reward, a = max(z), based on the\noutput from the encoding model.\n• Conversely, with a probability of ϵ, the system explores\nby randomly selecting an arm, facilitating the discovery\nof potentially more effective retrieval methods.\nThis strategy enables the system to predominantly rely\non the best-known actions to maximize immediate rewards\nwhile maintaining the flexibility to explore new possibilities.\nThis approach is essential to mitigate the risk of converging\nto a locally optimal model due to partial information feed-\nback, fostering the discovery of superior long-term solutions\nthrough randomized exploration.\nLearning Algorithm:\nAfter selecting a retrieval method,\nour model updates based on the observation associated with\nthe chosen method, but it does not have access to the infor-\nmation from methods not selected (i.e., partial information\nfeedback). Inspired by ”offline-to-online” learning(Lee et al.\n2022; Guo et al. 2024), we first pre-train the model in an\noffline environment to learn a robust initial strategy. Subse-\nquently, we fine-tune the model in an online setting using\npartial user feedback, allowing it to adapt continuously to\nreal-world conditions.\nTraditional RAG systems often focus on optimizing\nmodel accuracy. However, real-world applications of RAG\nsystems demand not only accuracy but also real-time respon-\nsiveness, introducing the need for multi-objective optimiza-\ntion. We use the Generalized Gini Index (Weymark 1981)\nto balance system performance with retrieval time, ensuring\nboth accuracy and efficiency are optimized simultaneously.\nDuring training, we use detailed evaluation metrics, in-\ncluding informativeness measures like hit and recall, to op-\ntimize for accuracy and coverage. Retrieval latency is also\nused as feedback to enhance efficiency. In testing, we sim-\nulate an online environment with a hit value (0 or 1) to ap-\nproximate binary user feedback. This offline-to-online learn-\ning approach ensures the model is well-prepared before de-\nployment and can adapt effectively to dynamic user interac-\ntions.\nThe methodology underpinning our approach is detailed\nin Algorithm 1. We have designed our system with a focus\non three critical objectives to evaluate the performance of\nthe retrieval methods comprehensively, enhancing the over-\nall functionality of our RAG system. Each query’s final re-\nsponse, generated by the LLM in natural language, is as-\nsessed according to these objectives, which include accuracy\nand efficiency metrics.\nAccuracy Metrics: For accuracy, we consider two key\nmetrics: hit (h, whether the response contains the correct\nanswer) and recall (rc, which assesses the system’s ability\nto retrieve all relevant items). These metrics are crucial for"
  },
  {
    "type": "text",
    "content": "Algorithm 1: Deep GGI-MO bandit enhanced RAG learning\nalgorithm\n1: Input: The query context set X, pre-trained language\nmodel parameters θ.\n2: Initialize: Set equal initial weights for the w.\n3: for x ∈X do\n4:\nEncode the query x and obtain the estimated action\ndistribution z = fθ(x).\n5:\nSelect an retriever (arm) a based on the selection\nstrategy described in Section 2.2.\n6:\nObserve the retrieval context to compute the loss\ncomponents as per Eq. (2) and the execution time d\nfor the retrieval process.\n7:\nUpdate the model weights θ by minimizing the loss\nLossGGI(θ) using gradient descent.\n8: end for\n9: Output: Updated model weights θ.\nassessing the precision and completeness of the system.\nEfficiency Metrics: Efficiency is evaluated based on the\nmean delay time (di) experienced by each retrieval method\nwithin the system. We utilize a distribution σ(di) to quanti-\ntatively represent each method’s efficiency. This distribution\nhelps the model understand the temporal performance across\ndifferent retrieval strategies, ensuring the system delivers not\nonly accurate but also timely responses.\nσ(di) =\ne1/di\nPK\nj=1 e1/dj ,\n(1)\nwhere methods with longer delays are assigned lower values,\nthus incentivizing quicker retrieval methods.\nMulti-Objective Optimization with GGI: To balance\nthese objectives, we compute the multi-objective GGI value,\nwhich integrates accuracy and efficiency metrics, further de-\ntail of GGI property can be found in Section 6.1. The GGI\nvalues for each objective are calculated as follows:\nl1 = MSE(max(fθ(x)), h),\n(Loss- Accuracy - Hit)\n(2)\nl2 = MSE(max(fθ(x)), rc),\n(Loss-Accuracy - Recall)\n(3)\nl3 = KLDiv(fθ(x), σ(di)),\n(Loss- Efficiency)\n(4)\nEach loss component li corresponds to a specific objective:\n• l1 and l2 measures the deviation in accuracy, encouraging\nthe model to select a method with a high probability pro-\nduce high recall and hit retrieval methods.\n• l3 quantifies the efficiency using the Kullback-Leibler Di-\nvergence (KLDiv) between the predicted arm selection\ndistribution from the model and the efficiency distribution\nσ(di) encourage the model to select an efficient retrieval\nmethod.\nThe aggregate loss function to be minimized, representing\nthe overall GGI, is then given by:\nLoss = GGIw(l) =\nD\nX\ni=1\nwi(li)τ = wT (l)τ\n(5)\nwhere w1 > w2 > · · · > wd > 0 and τ permutes the\nelements of l such that (li)τ > (li+1)τ.\nIn Equation 5, the GGI function aggregates the individual\nloss components, weighted by wi, to update the parameter θ,\noptimizing towards a better response quality with satisfying\nuser experience.\n3\nExperiment\n3.1\nDataset & Setup\nDatasets: We evaluate our systems on two KGQA\ndatasets WebQSP (Yih et al. 2016) and ComplexWebQues-\ntions (CWQ) (Talmor and Berant 2018) which contain up to\n4-hop questions. The statistics of the datasets are given in\nTable 5.\nBaselines: To valid the effectiveness of our MAB-\nenhanced KG-based RAG system under stationary environ-\nment, we compared it with state-of-the-art KG-based RAG\nsystems, including the query language-based RAG: Struct-\nGPT (Jiang et al. 2023b), ChatKBQA(Luo et al. 2023a),\nLLM agent-based RAG: Think-on-Graph (Sun et al. 2023)\nand Reason-on-Graph (Luo et al. 2023c), and dense retrieval\nbased RAG (Zhang et al. 2023; Yu et al. 2022).\nEvaluation Metrics: Following previous works, we eval-\nuate the performance of our Retrieval-Augmented Genera-\ntion system, all results are assessed based on the final gener-\nated response’s hit rate and recall. We ran at least ten inde-\npendent rounds with different seeds and reported the results\nas mean ± standard deviation to ensure the stability of our\nfindings.\nImplementations: We consistently use Llama-2-7b-chat-\nhf (Touvron et al. 2023) as the LLM generator, applying a\nstandard RAG prompt (LlamaIndex 2024) across all meth-\nods to ensure a fair comparison. All experiments are con-\nducted on the Nvidia Tesla V100 graphical card with the\nIntel Xeon Platinum 8255C CPU. See Section 6.3 for detail\nset up.\n3.2\nResearch Questions and Main Results\nRQ1: Can our Multi-Armed Bandit enhanced\nRetrieval-Augmented Generation system effectively im-\nprove performance compared to RAG systems that rely\non a single retrieval method?\nThe comparative analysis, summarized in Table 1, re-\nvealed that our MAB-enhanced RAG system demonstrated\nsuperior performance across both datasets. Notably, on the\nCWQ dataset, which poses more intricate multi-hop rea-\nsoning challenges, our method exceeds the next-best perfor-\nmance by nearly 2% in hit rate and over 2.5% in recall.\nWe present examples of our MAB-enhanced RAG sys-\ntems superior case. In the first case Fig. 7 derived from the\nchallenging CWQ dataset, the query pertains to the birth-\nplace of the lyricist for ”Stop Standing There.” Dense re-\ntrieval fails to relate the query to relevant information, and\nwhile the SPARQL retriever approaches a correct formula-\ntion, it ultimately generates a wrong query language. Thanks\nto the reasoning ability of LLM, the LLM-based KG agent\nsuccessfully retrieves the related triplets from the knowledge"
  },
  {
    "type": "text",
    "content": "Table 1: Results under Stationary environment\nRetriever Type\nMethod\nWebQSP\nCWQ\nHit ↑\nRecall ↑\nHit ↑\nRecall ↑\nDense Retrieval\nBGE (Zhang et al. 2023)\n63.03\n44.43\n52.46\n46.68\nDECAF (Yu et al. 2022)\n71.37\n50.93\n47.46\n41.47\nKG Query Languge Retrieval\nStructGPT (Jiang et al. 2023b)\n75.56\n55.26\n\\\n\\\nChatKBQA (Luo et al. 2023a)\n80.77\n64.31\n77.37\n69.46\nLLM agent Retreival\nThink-on-graph (Sun et al. 2023)\n66.64\n47.24\n58.90\n52.49\nReason-on-graph (Luo et al. 2023c)\n85.70\n75.07\n56.63\n52.38\nEnsemble (DECAF+ChatKBQA+Reason-on-graph)\n83.74\n67.52\n67.93\n68.01\nStatic Router\nLLM Router (lla 2024)\n82.48\n68.9\n65.75\n59.33\nNN-Router (Reis et al. 2019)\n86.20\n75.03\n78.53\n71.52\nOurs\nGGI-MAB\n86.64\n75.60\n79.35\n72.02\nTable 2: Results under Non-stationary environment (mean ± std)\nNon-stationarity\nMethod\nTest Hit ↑\nTest Recall ↑\nTest Retrieval Delay ↓\n(second per query)\nRetriever\nupdate\nRetrieval Ensemble\n83.74 ± 0.58\n67.52 ± 0.77\n15.00 ± 0.00\nOffline MO-MAB\n82.25 ± 2.18\n66.05 ± 2.56\n13.32 ± 1.90\nNN Router (Reis et al. 2019)\n81.48 ± 0.28\n64.90 ± 0.23\n14.09 ± 0.42\nLLM Router (lla 2024)\n82.19 ± 0.47\n67.11 ± 0.52\n10.36 ± 3.98\nOurs\n84.80 ± 0.39\n72.24 ± 0.71\n5.88 ± 0.99\nDomain\nshift\nRetrieval Ensemble\n67.93 ± 0.61\n68.01± 0.34\n15.00 ± 0.00\nOffline MO-MAB\n64.76 ± 4.40\n61.32 ± 2.90\n7.78 ± 0.44\nNN Router (Reis et al. 2019)\n69.57 ± 4.52\n63.99 ± 3.94\n7.65 ± 1.81\nLLM Router (lla 2024)\n65.75 ± 0.16\n59.33 ± 0.25\n9.39 ± 0.06\nOurs\n76.35 ± 0.69\n69.47 ± 0.76\n11.63 ± 0.28\ngraph and enables our MAB Enhanced RAG system to give\nan accurate response.\nIn the second case Fig. 3, from the WebQSP dataset where\nthe user queries, ”What are some books that Mark Twain\nwrote?” This question is challenging in terms of achieving\nhigh recall since all retrieval methods can provide related\ncontext, but not all can accurately list the books. Our MAB-\nenhanced RAG system effectively selects the appropriate\nmethods (SPARQL generator) to achieve the highest recall,\nsignificantly outperforming individual retrieval approaches.\nOur MAB-enhanced RAG system, effectively optimizes\nthe selection process of retrieval methods, thereby proving\nto be highly effective in improving overall system perfor-\nmance. Furthermore, as illustrated in MAB enhanced RAG\nsystems with LLM variants, we evaluate our method across\ndifferent Large Language Model generators to prove the ro-\nbustness of our system.\nRQ2: Can the MAB enhanced RAG system adapts dy-\nnamically to the non-stationary nature of real-world en-\nvironments, ensuring that they continuously meet evolv-\ning query demands and operational conditions?\nTo evaluate our methods under non-stationary environ-\nments, we use two non-stationary settings: (1) we employed\nthe KG agent-based retrieval method (Sun et al. 2023) dur-\ning the training phase. For online testing, we switched to\n(Luo et al. 2023c) a method with superior performance, to\nsimulate the effect of upgrading backend retrievers inde-\npendently to enhance system functionality. This approach\ntests the system’s ability to adapt seamlessly to improve-\nments in retrieval methods, reflecting real-world conditions\nwhere continuous updates are crucial for maintaining sys-\ntem efficacy. (2) To simulate the shift in query domains re-\nsulting from changes in trending topics, we initially train\nour methods using the WebQSP dataset. Subsequently, we\nevaluate the system’s adaptability by testing it on the Com-\nplexWebQuestions dataset. This approach allows us to as-\nsess how well the system can handle transitions between\ndifferent types of query complexities and content, mirroring\nreal-world scenarios where query characteristics can vary\nsignificantly due to external influences.\nThe results, as detailed in Table 2, in the first scenario,\nduring the retriever upgrade tests, our method demonstrated\nthe highest Test Hit and Test Recall rates f 84.80% and\n72.24% respectively, with a significantly reduced Test Re-\ntrieval Delay of 5.88 seconds per query. This improvement\nstems from our system’s capability to leverage partial infor-\nmation during testing to continuously refine the model. In\ncontrast, retrieval ensemble methods, which require running\nall retrieval methods, struggle with denoising information\nfrom different structures of retrieval results leading to the\nlongest Retrieval delay. Both the offline classifier and offline\nmulti-objective MAB (MO-MAB) were unable to adapt to"
  },
  {
    "type": "text",
    "content": "Table 3: Results of proposed multi-objective MAB algorithm under station environments (mean ± std)\nMethod\nTest Hit ↑\nTest Recall ↑\nTest Retrieval Delay ↓\n(second per query)\nBaselines\nUCB (Auer 2002)\n78.44 ± 6.07\n62.18 ± 10.08\n5.80 ± 6.08\nThompsom Sampling (Agrawal and Goyal 2013)\n84.12 ± 2.20\n71.82 ± 4.93\n6.60 ± 5.50\nLinUCB (Li et al. 2010)\n81.99 ± 2.91\n68.55 ± 5.30\n5.31 ± 2.80\nSO-Deep-MAB (Collier and Llorens 2018)\n86.79 ± 0.33\n75.18 ± 0.18\n11.1 ± 0.39\nMOU-UCB(Wanigasekara et al. 2019)\n85.55 ± 0.89\n75.05 ± 0.15\n5.52 ± 1.35\nOurs\nMO-MAB\n85.31 ± 0.55\n74.38 ± 0.48\n5.20 ± 0.58\nGGI-MO-MAB\n86.64 ± 0.29\n75.60 ± 0.38\n4.84 ± 0.81"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p5_8.png"
  },
  {
    "type": "text",
    "content": "Figure 3: Comparison of retrieval methods for the query,\n”What are some books that Mark Twain wrote?” Dense Re-\ntrieval is fast but has low recall, while KG-Agent-Retriever\nprovides broad coverage but is slow. Our system selects the\nSPARQL-Retriever (Luo et al. 2023a), which generates an\naccurate search language command for precise and efficient\nresults.\nthe upgrades, resulting in inferior performance.\nIn the second scenario, our approach effectively adapted\nto domain shifts by utilizing the slower KG agent retriever\nand SPARQL generator retrieval methods. Although it needs\nmore retrieval time at 11.63 seconds per query compared to\nsome offline methods, it significantly outperformed compar-\native methods in accuracy metrics, achieving a Test Hit rate\nof 76.35% and a Test Recall of 69.47%.\nThe results further highlight our system’s capacity to\ndynamically adjust operational parameters in response to\nevolving query complexities, ensuring high-quality user in-\nteractions even under challenging conditions.\nRQ3: How can the Generalized Gini Index be effec-\ntively utilized to balance multiple performance metrics\nin RAG systems\nIn Table 3 we evaluate our proposed method on the We-\nbQSP dataset, results highlight the effectiveness of the Gen-\neralized Gini Index enhanced Multi-Objective Multi-Armed\nBandit (GGI-MO-MAB), achieving the highest Test Hit rate\nand Test Recall, while maintaining the lowest retrieval de-\nlay compared to the baselines. Non-contextual baselines like\nUCB (Auer 2002) and Thompson Sampling (Agrawal and\nGoyal 2013) approximate only a single optimal retrieval\nmethod. LinUCB (Li et al. 2010) under-performs due to\nits inability to handle the high-dimensional, complex nat-\nural language embeddings. Single-objective deep contextual\nMAB models, while improving accuracy metrics such as Hit\nrate, often neglect retrieval time, adversely affecting user ex-\nperience. Our GGI-MO-MAB can also outperform multi-\nobjective baseline MOU-UCB (Wanigasekara et al. 2019).\nTo underscore the efficacy of our approach, we include an\nablation study comparing the GGI function to a learnable\nweight aggregation baseline (MO-MAB), confirming the ro-\nbust performance improvement of our method.\nRQ4: What are the effects of implementing multiple\nretrieval methods, such as dense retrieval and KG agent\nretrieval methods, on the response times and accuracy\nunder different real-world scenarios?\nThe comparison of different types of retrieval methods is\nshown in Fig. 4, we also employed the Jaccard Similarity\nCoefficient to assess the Hit metric across results. Our find-\nings reveal an average coefficient of 0.738, with the lowest\nobserved at 0.496, indicating the distinctiveness of the re-\nsults obtained by different retrieval strategies.\nMoreover, while methods such as ChatKBQA and\nReason-on-graph showed strong results on WebQSP, they\nwere less effective on the more challenging CWQ dataset,\nhighlighting the importance of retrieval method selection\nbased on the complexity and nature of the dataset. Our\nsystem’s consistent performance across different datasets\nunderscores its robustness and adaptability, making it par-\nticularly suitable for diverse real-world applications where\nquery demands and operational conditions can vary signifi-\ncantly.\nIn terms of response time, we observed significant differ-\nences in processing time; for instance, dense-vector retrieval\nmethods average around 1 second, whereas more complex\nmethods like ChatKBQA (Luo et al. 2023a), due to multiple"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p6_10.png"
  },
  {
    "type": "text",
    "content": "Figure 4: Confusion matrices comparing retrieval methods\n(Decaf, ChatKBQA, BGE, RoG) on WebQSP and CWQ\ndatasets, indicating distinctiveness among methods.\ninteractions with ChatGPT (OpenAI 2024) to get an exe-\ncutable query code, can take 15-30 seconds. These findings\nhighlight the trade-off between complexity and efficiency in\nretrieval operations.\nOur findings confirm that the choice of retrieval method\nsignificantly impacts the accuracy and efficiency of RAG\nsystems.\n4\nRelated Work\nKG-based RAG Systems: Retrieval-Augmented Gener-\nation (RAG)(Lewis et al. 2020) mitigates the hallucination\nissue of LLMs by retrieving external knowledge to enhance\nthe accuracy and reliability of generation content. Recent\nRAG advancements have increasingly incorporated Knowl-\nedge Graphs (KGs) (Luo et al. 2023c; Sun et al. 2023; Xu\net al. 2024; He et al. 2024), which store structured factual\ninformation, enabling more systematic reasoning by LLMs\n(Pan et al. 2024). KGs support diverse retrieval methods,\neach with different capabilities and costs, as detailed in Sec-\ntion 6.6.\nOur analysis of retrieval methods, discussed in Sec-\ntion 3.2, shows that current KG-based RAG systems(Luo\net al. 2023c; Sun et al. 2023; Xu et al. 2024; He et al. 2024)\npredominantly rely on a single retrieval method, which often\nfails to meet the varied demands of real-world applications.\nThese systems typically assume a stationary environment\nand remain static without subsequent fine-tuning, making\nthem unable to adapt to potential shifts in the query domain\nand upgrades of the backend retriever. To address these is-\nsues,our work aims to develop an MAB-enhanced RAG sys-\ntem that strategically combines multiple retrievers. By lever-\naging real-time feedback, our system can dynamically adjust\nretrieval strategies to meet the evolving demands of diverse\napplication scenarios of the RAG system effectively.\nTo our knowledge, the concurrent research by (Sawarkar,\nMangal, and Solanki 2024) is one of the few studies attempt-\ning to integrate multiple retrieval methods, but it focuses on\ntextual data sources and lacks the continuous optimization\ncrucial for RAG systems in non-stationary environments.\nMulti-Armed Bandit Algorithms: The Multi-Armed\nBandit (MAB) (Katehakis and Veinott Jr 1987) framework\noptimizes the balance between exploiting historical data\nand exploring new information. It includes two main types:\ncontext-free (Bubeck, Cesa-Bianchi et al. 2012), which op-\nerates without external information, and contextual bandits\n(Mahajan and Teneketzis 2008), which incorporate contex-\ntual data such as user features. Traditional contextual ban-\ndits assume a linear relationship between context and ex-\npected rewards (Slivkins 2011), but recent developments\nhave introduced non-linear models through deep learning\n(Collier and Llorens 2018; Zhou, Li, and Gu 2020; Shi et al.\n2023). The multi-objective contextual MAB (MOCMAB)\nalgorithm (Tekin and Tur˘gay 2018) maximizes rewards\nacross multiple objectives, managing both dominant and\nnon-dominant goals. Some approaches (Busa-Fekete et al.\n2017; Mehrotra, Xue, and Lalmas 2020) use the Generalized\nGini Index (GGI) to convert multi-objective challenges into\nsingle-objective optimizations, simplifying decision-making\nin dynamic environments.\nHowever, existing contextual bandit algorithms often as-\nsume reward is linear with respect to the context feature\n(Tekin and Tur˘gay 2018; Mehrotra, Xue, and Lalmas 2020;\nLi et al. 2010), limiting their representational capacity to\nmatch user query patterns with retrieval strategies effec-\ntively, or they focus solely on single-objective optimiza-\ntion (Collier and Llorens 2018; Zhou, Li, and Gu 2020; Shi\net al. 2023), which does not suffice for complex RAG sys-\ntems with requirements of performance and real-time limi-\ntation. Therefore, in this work, we adopt a non-linear multi-\nobjective contextual MAB model.\n5\nConclusion\nIn this work, we introduced a novel KG-based RAG\nframework enhanced by a Multi-Armed Bandit (MAB)\nmodel. By leveraging real-time user feedback, our system\ndynamically adapts to shifting query demands and backend\nupgrades. We further incorporated the Generalized Gini In-\ndex to balance multiple objectives, ensuring that the system\ndelivers both informative and timely responses.\nOur comprehensive evaluations on two well-established\nKBQA datasets, WebQuestionSP and ComplexWebQues-\ntions, demonstrate that our approach not only significantly\noutperforms baseline methods in non-stationary environ-\nments but also surpasses state-of-the-art KG-based RAG\nsystems in stationary settings. These results underscore the\nrobustness, adaptability, and practical applicability of our\nframework in real-world scenarios where query demands\nand operational conditions are constantly evolving."
  },
  {
    "type": "text",
    "content": "References\n2024.\nDefine Selector Module for Routing — Llama\nIndex\nDocumentation.\nhttps://docs.llamaindex.ai/en/\nstable/examples/retrievers/router retriever/#define-selector-\nmodule-for-routing. Accessed: 2024-08-07.\nAgrawal, S.; and Goyal, N. 2013. Thompson sampling for\ncontextual bandits with linear payoffs. In International con-\nference on machine learning, 127–135. PMLR.\nAlan, A. Y.; Aydın, ¨O.; and Karaarslan, E. 2024. A RAG-\nbased Question Answering System Proposal for Under-\nstanding Islam: MufassirQAS LLM.\nAvailable at SSRN\n4707470.\nAuer, P. 2002. Using confidence bounds for exploitation-\nexploration trade-offs.\nJournal of Machine Learning Re-\nsearch, 3(Nov): 397–422.\nAuer, P.; Cesa-Bianchi, N.; and Fischer, P. 2002. Finite-time\nanalysis of the multiarmed bandit problem. Machine learn-\ning, 47: 235–256.\nBaek, J.; Aji, A. F.; and Saffari, A. 2023.\nKnowledge-\naugmented\nlanguage\nmodel\nprompting\nfor\nzero-shot\nknowledge graph question answering.\narXiv preprint\narXiv:2306.04136.\nBang, Y.; Cahyawijaya, S.; Lee, N.; Dai, W.; Su, D.; Wilie,\nB.; Lovenia, H.; Ji, Z.; Yu, T.; Chung, W.; et al. 2023. A\nmultitask, multilingual, multimodal evaluation of chatgpt on\nreasoning, hallucination, and interactivity.\narXiv preprint\narXiv:2302.04023.\nBehnamGhader,\nP.;\nMiret,\nS.;\nand\nReddy,\nS.\n2023.\nCan Retriever-Augmented Language Models Reason? The\nBlame Game Between the Retriever and the Language\nModel. In Findings of the Association for Computational\nLinguistics: EMNLP 2023, 15492–15509.\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\nA.; et al. 2020. Language models are few-shot learners. Ad-\nvances in neural information processing systems, 33: 1877–\n1901.\nBubeck, S.; Cesa-Bianchi, N.; et al. 2012.\nRegret analy-\nsis of stochastic and nonstochastic multi-armed bandit prob-\nlems. Foundations and Trends® in Machine Learning, 5(1):\n1–122.\nBusa-Fekete, R.; Sz¨or´enyi, B.; Weng, P.; and Mannor, S.\n2017. Multi-objective bandits: Optimizing the generalized\nGini index. In International Conference on Machine Learn-\ning, 625–634. PMLR.\nChen, C.; Guo, C.; Chen, R.; Ma, G.; Zeng, M.; Liao, X.;\nZhang, X.; and Xie, S. ???? Training for Stable Explanation\nfor Free. In The Thirty-eighth Annual Conference on Neural\nInformation Processing Systems.\nChowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\nG.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\nGehrmann, S.; et al. 2023. Palm: Scaling language model-\ning with pathways. Journal of Machine Learning Research,\n24(240): 1–113.\nCollier, M.; and Llorens, H. U. 2018. Deep contextual multi-\narmed bandits. arXiv preprint arXiv:1807.09809.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nDu, W.; Chen, J.; Zhang, X.; Ma, Z.; and Liu, S. 2024.\nMolecule joint auto-encoding: trajectory pretraining with\n2D and 3D diffusion. In Proceedings of the 37th Interna-\ntional Conference on Neural Information Processing Sys-\ntems, NIPS ’23. Curran Associates Inc.\nDu, Z.; Qian, Y.; Liu, X.; Ding, M.; Qiu, J.; Yang, Z.;\nand Tang, J. 2021.\nGlm: General language model pre-\ntraining with autoregressive blank infilling. arXiv preprint\narXiv:2103.10360.\nEnnen, P.; Freddi, F.; Lin, C.-J.; Kung, P.-N.; Wang, R.;\nYang, C.-Y.; Shiu, D.-s.; and Bernacchia, A. 2023.\nHi-\nerarchical Representations in Dense Passage Retrieval for\nQuestion-Answering. In Proceedings of the Sixth Fact Ex-\ntraction and VERification Workshop (FEVER), 17–28.\nGamage, G.; Mills, N.; De Silva, D.; Manic, M.; Moraliyage,\nH.; Jennings, A.; and Alahakoon, D. 2024.\nMulti-Agent\nRAG Chatbot Architecture for Decision Support in Net-Zero\nEmission Energy Systems. In 2024 IEEE International Con-\nference on Industrial Technology (ICIT), 1–6. IEEE.\nGuo, S.; Zou, L.; Chen, H.; Qu, B.; Chi, H.; Yu, P. S.; and\nChang, Y. 2024. Sample Efficient Offline-to-Online Rein-\nforcement Learning. IEEE Transactions on Knowledge and\nData Engineering, 36(3): 1299–1310.\nHe, X.; Tian, Y.; Sun, Y.; Chawla, N. V.; Laurent, T.; LeCun,\nY.; Bresson, X.; and Hooi, B. 2024. G-Retriever: Retrieval-\nAugmented Generation for Textual Graph Understanding\nand Question Answering. arXiv preprint arXiv:2402.07630.\nJenkins, S. 2017. The measurement of income inequality. In\nEconomic inequality and poverty, 3–38. Routledge.\nJi, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii, E.;\nBang, Y. J.; Madotto, A.; and Fung, P. 2023. Survey of hal-\nlucination in natural language generation. ACM Computing\nSurveys, 55(12): 1–38.\nJiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;\nChaplot, D. S.; Casas, D. d. l.; Bressand, F.; Lengyel, G.;\nLample, G.; Saulnier, L.; et al. 2023a. Mistral 7B. arXiv\npreprint arXiv:2310.06825.\nJiang, J.; Zhou, K.; Dong, Z.; Ye, K.; Zhao, W. X.; and Wen,\nJ.-R. 2023b. Structgpt: A general framework for large lan-\nguage model to reason over structured data. arXiv preprint\narXiv:2305.09645.\nKarpukhin, V.; Oguz, B.; Min, S.; Lewis, P. S.; Wu, L.;\nEdunov, S.; Chen, D.; and Yih, W.-t. 2020.\nDense Pas-\nsage Retrieval for Open-Domain Question Answering. In\nEMNLP (1), 6769–6781.\nKatehakis, M. N.; and Veinott Jr, A. F. 1987. The multi-\narmed bandit problem: decomposition and computation.\nMathematics of Operations Research, 12(2): 262–268.\nLangford, J.; and Zhang, T. 2007. The epoch-greedy algo-\nrithm for multi-armed bandits with side information. Ad-\nvances in neural information processing systems, 20.\nLee, S.; Seo, Y.; Lee, K.; Abbeel, P.; and Shin, J. 2022.\nOffline-to-online reinforcement learning via balanced replay"
  },
  {
    "type": "text",
    "content": "and pessimistic q-ensemble. In Conference on Robot Learn-\ning, 1702–1712. PMLR.\nLewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.;\nGoyal, N.; K¨uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨aschel,\nT.; et al. 2020.\nRetrieval-augmented generation for\nknowledge-intensive nlp tasks. Advances in Neural Infor-\nmation Processing Systems, 33: 9459–9474.\nLi, L.; Chu, W.; Langford, J.; and Schapire, R. E. 2010. A\ncontextual-bandit approach to personalized news article rec-\nommendation. In Proceedings of the 19th international con-\nference on World wide web, 661–670.\nLlamaIndex. 2024. Prompt Engineering for RAG. Accessed:\n2024-05-16.\nLuo, H.; Tang, Z.; Peng, S.; Guo, Y.; Zhang, W.; Ma, C.;\nDong, G.; Song, M.; Lin, W.; et al. 2023a. Chatkbqa: A\ngenerate-then-retrieve framework for knowledge base ques-\ntion answering with fine-tuned large language models. arXiv\npreprint arXiv:2310.08975.\nLuo, L.; Ju, J.; Xiong, B.; Li, Y.-F.; Haffari, G.; and Pan, S.\n2023b. Chatrule: Mining logical rules with large language\nmodels for knowledge graph reasoning.\narXiv preprint\narXiv:2309.01538.\nLuo, L.; Li, Y.-F.; Haffari, G.; and Pan, S. 2023c. Reasoning\non graphs: Faithful and interpretable large language model\nreasoning. arXiv preprint arXiv:2310.01061.\nMahajan, A.; and Teneketzis, D. 2008. Multi-armed bandit\nproblems. In Foundations and applications of sensor man-\nagement, 121–151. Springer.\nMehrotra, R.; Xue, N.; and Lalmas, M. 2020. Bandit based\noptimization of multiple objectives on a music streaming\nplatform. In Proceedings of the 26th ACM SIGKDD inter-\nnational conference on knowledge discovery & data mining,\n3224–3233.\nOpenAI. 2024. ChatGPT. https://openai.com/chatgpt. Ac-\ncessed: 2024-05-20.\nOpenAI, R. 2023. Gpt-4 technical report. arxiv 2303.08774.\nView in Article, 2(5).\nPan, S.; Luo, L.; Wang, Y.; Chen, C.; Wang, J.; and Wu,\nX. 2024. Unifying large language models and knowledge\ngraphs: A roadmap. IEEE Transactions on Knowledge and\nData Engineering.\nPetroni, F.; Piktus, A.; Fan, A.; Lewis, P.; Yazdani, M.;\nDe Cao, N.; Thorne, J.; Jernite, Y.; Karpukhin, V.; Maillard,\nJ.; et al. 2020. KILT: a benchmark for knowledge intensive\nlanguage tasks. arXiv preprint arXiv:2009.02252.\nReis, J.; Rocha, M.; Phan, T. K.; Griffin, D.; Le, F.; and\nRio, M. 2019. Deep Neural Networks for Network Routing.\nIn 2019 International Joint Conference on Neural Networks\n(IJCNN), 1–8.\nSanh, V.; Debut, L.; Chaumond, J.; and Wolf, T. 2019. Dis-\ntilBERT, a distilled version of BERT: smaller, faster, cheaper\nand lighter. arXiv preprint arXiv:1910.01108.\nSawarkar, K.; Mangal, A.; and Solanki, S. R. 2024. Blended\nRAG: Improving RAG (Retriever-Augmented Generation)\nAccuracy with Semantic Search and Hybrid Query-Based\nRetrievers. arXiv preprint arXiv:2404.07220.\nShi, Q.; Xiao, F.; Pickard, D.; Chen, I.; and Chen, L. 2023.\nDeep neural network with linucb: A contextual bandit ap-\nproach for personalized recommendation.\nIn Companion\nProceedings of the ACM Web Conference 2023, 778–782.\nSlivkins, A. 2011. Contextual Bandits with Similarity In-\nformation. In Kakade, S. M.; and von Luxburg, U., eds.,\nProceedings of the 24th Annual Conference on Learning\nTheory, volume 19 of Proceedings of Machine Learning Re-\nsearch, 679–702. Budapest, Hungary: PMLR.\nSun, J.; Xu, C.; Tang, L.; Wang, S.; Lin, C.; Gong, Y.; Shum,\nH.-Y.; and Guo, J. 2023. Think-on-Graph: Deep and Re-\nsponsible Reasoning of Large Language Model with Knowl-\nedge Graph. arXiv:2307.07697.\nSun, W.; Qin, Z.; Li, D.; Shen, X.; Qiao, Y.; and Zhong,\nY. 2024a.\nLinear Attention Sequence Parallelism.\narXiv\npreprint arXiv:2404.02882.\nSun, W.; Qin, Z.; Sun, W.; Li, S.; Li, D.; Shen, X.; Qiao,\nY.; and Zhong, Y. 2024b. CO2: Efficient distributed train-\ning with full communication-computation overlap.\narXiv\npreprint arXiv:2401.16265.\nTalmor, A.; and Berant, J. 2018. The web as a knowledge-\nbase for answering complex questions.\narXiv preprint\narXiv:1803.06643.\nTekin, C.; and Tur˘gay, E. 2018. Multi-objective contextual\nmulti-armed bandit with a dominant objective. IEEE Trans-\nactions on Signal Processing, 66(14): 3799–3813.\nTouvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.;\nBabaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale,\nS.; et al. 2023. Llama 2: Open foundation and fine-tuned\nchat models. arXiv preprint arXiv:2307.09288.\nWanigasekara, N.; Liang, Y.; Goh, S. T.; Liu, Y.; Williams,\nJ. J.; and Rosenblum, D. S. 2019. Learning Multi-Objective\nRewards and User Utility Function in Contextual Bandits for\nPersonalized Ranking. In IJCAI, volume 19, 3835–3841.\nWeymark, J. A. 1981. Generalized Gini inequality indices.\nMathematical Social Sciences, 1(4): 409–430.\nXie, T.; Wu, C. H.; Shi, P.; Zhong, R.; Scholak, T.; Ya-\nsunaga, M.; Wu, C.-S.; Zhong, M.; Yin, P.; Wang, S. I.; et al.\n2022. UnifiedSKG: Unifying and Multi-Tasking Structured\nKnowledge Grounding with Text-to-Text Language Models.\nIn Proceedings of the 2022 Conference on Empirical Meth-\nods in Natural Language Processing, 602–631.\nXu, Z.; Cruz, M. J.; Guevara, M.; Wang, T.; Deshpande, M.;\nWang, X.; and Li, Z. 2024. Retrieval-Augmented Genera-\ntion with Knowledge Graphs for Customer Service Question\nAnswering. arXiv preprint arXiv:2404.17723.\nYih, W.-t.; Richardson, M.; Meek, C.; Chang, M.-W.; and\nSuh, J. 2016.\nThe value of semantic parse labeling for\nknowledge base question answering. In Proceedings of the\n54th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers), 201–206.\nYu, D.; Zhang, S.; Ng, P.; Zhu, H.; Li, A. H.; Wang, J.;\nHu, Y.; Wang, W.; Wang, Z.; and Xiang, B. 2022.\nDe-\ncaf: Joint decoding of answers and logical forms for ques-\ntion answering over knowledge bases.\narXiv preprint\narXiv:2210.00063."
  },
  {
    "type": "text",
    "content": "Zhang, P.; Xiao, S.; Liu, Z.; Dou, Z.; and Nie, J.-Y. 2023.\nRetrieve anything to augment large language models. arXiv\npreprint arXiv:2310.07554.\nZhou, D.; Li, L.; and Gu, Q. 2020. Neural contextual bandits\nwith ucb-based exploration. In International Conference on\nMachine Learning, 11492–11502. PMLR.\n6\nAppendix\n6.1\nGeneralized Gini Index\nTo further leverage the unique strengths of each method\nand enhance the overall efficacy of the RAG pipeline. This\nnecessitates the formulation of a multi-objective optimiza-\ntion problem.\nThe Generalized Gini Index (GGI) emerges as a crucial\ntool in this context, offering a sophisticated framework for\nequitably balancing diverse criteria in multi-objective opti-\nmization scenarios. The need for such an optimization arises\nfrom the varied and often conflicting objectives associated\nwith different retrieval methods. For instance, while one\nmethod may excel in accuracy, another might offer benefits\nin terms of speed. The challenge, therefore, lies in achieving\nan optimal balance that maximizes the overall performance\nof the RAG system.\nGGI has been characterized by (Weymark 1981). It en-\ncodes both efficiency as it is monotone with Pareto domi-\nnance and fairness as it is non-increasing with Pigou-Dalton\ntransfers(Jenkins 2017). Informally, a Pigou-Dalton transfer\ninvolves increasing a lower-valued objective while decreas-\ning a higher-valued objective by an equivalent amount, with-\nout altering the order between the two objectives. This oper-\nation seeks to equilibrate the cost vector. Formally, the GGI\nadheres to the following fairness principle: for any xi < xj,\n∀ϵ ∈(0, xj −xi),\nGw(x + ϵei −ϵej) ≤Gw(x)\n(6)\nwhere ei and ej are two vectors of the canonical basis. Con-\nsequently, among vectors with an equal sum, the optimal\ncost vector (with respect to GGI) is the one that features\nuniform values across all objectives, provided that such a\ndistribution is feasible.\n6.2\nMAB enhanced RAG systems with LLM\nvariants\nWe evaluated our MAB-enhanced RAG system using var-\nious LLM generators, including Chatglm3 (Du et al. 2021)\nand Mistral (Jiang et al. 2023a). The results, depicted in\nFig. 5, demonstrate that our system significantly improves\nRAG performance compared to traditional systems that uti-\nlize only a single retriever. This enhancement underscores\nthe robustness and adaptability of our MAB-enhanced RAG\napproach.\n6.3\nImplementation detail\nTo leverage the strengths of various retrieval methods, our\nMAB-enhanced RAG system, along with other router-based\nRAG approaches, utilizes DECAF(Yu et al. 2022), ChatK-\nBQA(Luo et al. 2023a), and Reason-on-Graph(Luo et al."
  },
  {
    "type": "image",
    "path": "extracted_images/img_p9_15.png"
  },
  {
    "type": "text",
    "content": "Figure 5: MAB enhanced RAG systems with LLM variants\nunder stationary environments\nMethod\nTest Hit\nTest Recall\nTest Retrieval Delay\nGGI-MO-MAB (offline)\n61.70 ± 2.08\n42.50 ± 2.62\n4.84 ± 0.81\nStatic NN-Router\n64.99 ± 1.24\n46.23 ± 1.58\n5.44 ± 0.54\nGGI-MO-MAB (online)\n77.55 ± 2.40\n60.07 ± 3.29\n11.23 ± 3.21\nTable 4: Performance comparison under system degradation\nscenario\n2023c) as its action space. In Table 1, the term “Ensemble”\nand in Table 2, “Retrieval Ensemble” refer to configurations\nwhere multiple retrievers operate in a complementary man-\nner. Following the methodology outlined in (lla 2024) the\nLLM Router is referring to a prompt-based GPT-4 (32k)\nrouter accessed via the OpenAI API. Approaches such as\nthose proposed by (Sun et al. 2024b,a) can be utilized to ac-\ncelerate the training process.\n6.4\nCase study\nWe further present a case study Fig. 6 to illustrate the ef-\nfectiveness of our system, the query inquires about influ-\nences on Frank Lloyd Wright. While dense retrieval pro-\nvides a fast response, it introduces noisy and irrelevant\ndata. The LLM agent retriever, though accessing structured\nknowledge graphs, fails to deliver accurate information, fo-\ncusing instead on peripheral details like professions. How-\never, the SPARQL-retriever can give a very accurate query\ncode for this question with clear conditions, and successfully\nfetch all results that support our systems to offer a nuanced\nand accurate response.\n6.5\nExperiment of additional non-stationarity\nAs shown in Table 4, we simulate the scenario where one\nof the retrieval services fails, (unable to return any docu-\nments) and requires router to swiftly reorganize the queries\nto other retrieval methods.\n6.6\nRetrieval methods on KG\nDense retrieval: Dense retrieval methods (Zhang et al.\n2023; Karpukhin et al. 2020) standardize and segment di-"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p10_17.png"
  },
  {
    "type": "text",
    "content": "Figure 6: SPARQL-Based Retriever gives the most accurate\ncontext"
  },
  {
    "type": "image",
    "path": "extracted_images/img_p10_19.png"
  },
  {
    "type": "text",
    "content": "Figure 7: KG Agent gives the most accurate context\nverse document formats like PDF, HTML, Word, and Mark-\ndown into plain text, which is then transformed into vec-\ntor embeddings for efficient searching (Karpukhin et al.\n2020). Utilizing a pre-trained language model (Devlin\net al. 2018), DPR creates dense embeddings from question-\npassage pairs, significantly enhancing accuracy over BM25\nand ORQA in open Natural Questions. Additionally, recent\ndevelopments by (Zhang et al. 2023) have tailored embed-\nding models to meet the varied retrieval demands of LLMs\nwith techniques like knowledge distillation and multi-task\nfine-tuning.\nThere are two main approaches to applying dense retrieval\nto Knowledge Graph data: directly searching the textual data\n(e.g. Wikipedia) that constitutes the KG (Ennen et al. 2023;\nKarpukhin et al. 2020), and linearizing KGs into text corpora\n(Yu et al. 2022; Xie et al. 2022), which translates structured\nknowledge into natural language form.\nDense retrieval methods are typically fast with pre-built\nvector bases, but it rely on embedding models for query rea-\nsoning, often falling short in complex, multi-hop retrieval\ntasks that demand greater analytical depth (BehnamGhader,\nMiret, and Reddy 2023).\nKG Query Language Retrieval: Due to the structured\nrepresentation and storage, it is efficient to access structured\ndata using query languages (e.g. SPARQL) or specific al-\ngorithms (e.g., triple search for knowledge graphs). ChatK-\nBQA (Luo et al. 2023a) proposes generating the logical\nform with fine-tuned LLMs first, then retrieving and replac-\ning entities and relations through an unsupervised retrieval\nmethod, which improves both generation and retrieval more\nstraightforwardly. StructGPT (Jiang et al. 2023b) constructs\nthe specialized interfaces to collect relevant evidence from\nstructured data, and let LLMs concentrate on the reasoning\ntask based on the collected information (Chen et al.).\nKG agent-based retrieval: Differing from SPARQL gen-\nerator retrieval, LLM agent-based retrieval adopts a tightly\ncoupled ”LLM-KG” paradigm. In this setup, agents such\nas LLMs navigate through relations and entities on Knowl-\nedge Graphs and construct a reasoning path for answering\nqueries. (Sun et al. 2023) introduces a new approach called\nThink-on-Graph (ToG), in which the LLM agent iteratively\nexecutes beam search on KG, discovers the most promis-\ning reasoning paths, and returns the most likely reasoning\nresults. (Luo et al. 2023c) presents a planning retrieval-\nreasoning framework, where RoG first generates relation\npaths grounded by KGs as faithful plans. These plans are\nthen used to retrieve valid reasoning paths from the KGs for\nLLMs to conduct faithful reasoning(Du et al. 2024).\n6.7\nRAG Prompts Used in Experiments\nListing 1: RAG prompt\nSystem prompt:\nBased on the context information\nprovided, and not on prior knowledge,\nplease answer the given question.\nContext: {context}\nQuestion:\nPlease answer the query: {query}\n6.8\nStatistics of datasets\nTable 5: Statistics of datasets.\nDatasets\nTrain\nTest\nMax hop\nWebQSP\n2,826\n1,628\n2\nCWQ\n27,639\n3,531\n4"
  }
]